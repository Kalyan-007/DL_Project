{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3,1280)\n",
    "# cap.set(4,720)\n",
    "\n",
    "# while True:\n",
    "#     success, img = cap.read()\n",
    "#     cv2.imshow(\"Image\",img)\n",
    "#     cv2.waitKey(1)\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# with mp_hands.Hands(\n",
    "#     model_complexity=0,\n",
    "#     min_detection_confidence=0.5,\n",
    "#     min_tracking_confidence=0.5) as hands:\n",
    "#     for i in range(300):\n",
    "#         success, image = cap.read()\n",
    "#         if not success:\n",
    "#             print(\"Ignoring empty camera frame.\")\n",
    "#         # If loading a video, use 'break' instead of 'continue'.\n",
    "\n",
    "#         # To improve performance, optionally mark the image as not writeable to\n",
    "#         # pass by reference.\n",
    "#         image.flags.writeable = False\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         results = hands.process(image)\n",
    "\n",
    "#         # Draw the hand annotations on the image.\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "#         if results.multi_hand_landmarks:\n",
    "#             for hand_landmarks in results.multi_hand_landmarks:\n",
    "#                 print(f\"[INFO] {i} {hand_landmarks}\")\n",
    "#                 mp_drawing.draw_landmarks(\n",
    "#                     image,\n",
    "#                     hand_landmarks,\n",
    "#                     mp_hands.HAND_CONNECTIONS,\n",
    "#                     mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "#                     mp_drawing_styles.get_default_hand_connections_style())\n",
    "#         # Flip the image horizontally for a selfie-view display.\n",
    "#         cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "#         if cv2.waitKey(5) & 0xFF == 27:\n",
    "#             break\n",
    "# cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILES = ['2plams.jpg','1plam.jpg']\n",
    "data_points = []\n",
    "with mp_hands.Hands(static_image_mode=True,    max_num_hands=2,    min_detection_confidence=0.5) as hands:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv2.flip(cv2.imread(file), 1)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print handedness and draw hand landmarks on the image.\n",
    "    print('Handedness:', results.multi_handedness)\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    image_height, image_width, _ = image.shape\n",
    "    annotated_image = image.copy()\n",
    "    land_marks = []\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        print('hand_landmarks:', hand_landmarks)\n",
    "        land_marks.append(hand_landmarks)\n",
    "        print(\n",
    "          f'Index finger tip coordinates: (',\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})')\n",
    "        mp_drawing.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks,\n",
    "          mp_hands.HAND_CONNECTIONS,\n",
    "          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "          mp_drawing_styles.get_default_hand_connections_style())\n",
    "    cv2.imwrite('annotated_'+str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "    data_points.append(land_marks)\n",
    "    # Draw hand world landmarks.\n",
    "    if not results.multi_hand_world_landmarks:\n",
    "      continue\n",
    "    for hand_world_landmarks in results.multi_hand_world_landmarks:\n",
    "      mp_drawing.plot_landmarks(\n",
    "        hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73499cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f825dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_points[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86926c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "input_dir = Path.cwd()/\"dataset\"\n",
    "\n",
    "IMAGE_FILES = list(input_dir.rglob(\"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(IMAGE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILES[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6ace5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7846458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print ([name for name in os.listdir(\".\") if os.path.isdir(name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc941141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = './dataset'\n",
    "\n",
    "sub_folders = [name for name in os.listdir(folder) if os.path.isdir(os.path.join(folder, name))]\n",
    "\n",
    "print(sub_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c528f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67231dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_points = []\n",
    "with mp_hands.Hands(static_image_mode=True,    max_num_hands=2,    min_detection_confidence=0.5) as hands:\n",
    "    \n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    file = str(file)\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv2.flip(cv2.imread(file), 1)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print handedness and draw hand landmarks on the image.\n",
    "#     print('Handedness:', results.multi_handedness)\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    image_height, image_width, _ = image.shape\n",
    "    annotated_image = image.copy()\n",
    "    land_marks = {}\n",
    "    for hand_type, hand_landmarks in zip(results.multi_handedness , results.multi_hand_landmarks):\n",
    "#         print('hand_landmarks:', hand_landmarks)\n",
    "#         land_marks.append(hand_landmarks)\n",
    "        land_marks[hand_type.classification[0].label] = hand_landmarks\n",
    "#         print(\n",
    "#           f'Index finger tip coordinates: (',\n",
    "#           f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "#           f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})')\n",
    "        mp_drawing.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks,\n",
    "          mp_hands.HAND_CONNECTIONS,\n",
    "          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "          mp_drawing_styles.get_default_hand_connections_style())\n",
    "    cv2.imwrite('annotated_R'+str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "    data_points.append(land_marks)\n",
    "    # Draw hand world landmarks.\n",
    "    if not results.multi_hand_world_landmarks:\n",
    "      continue\n",
    "#     for hand_world_landmarks in results.multi_hand_world_landmarks:\n",
    "#       mp_drawing.plot_landmarks(\n",
    "#         hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac476a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  E  [INFO] B\n",
      "B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  [INFO] K\n",
      "K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  K  [INFO] L\n",
      "L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  L  [INFO] 2\n",
      "2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  [INFO] Y\n",
      "Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  Y  [INFO] 5\n",
      "5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  [INFO] P\n",
      "P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  P  [INFO] W\n",
      "W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  W  "
     ]
    }
   ],
   "source": [
    "\n",
    "data_points = []\n",
    "with mp_hands.Hands(static_image_mode=True,    max_num_hands=2,    min_detection_confidence=0.5) as hands:\n",
    "    for fld_name in sub_folders:\n",
    "        input_dir = Path.cwd()/f\"dataset/{fld_name}\"\n",
    "        IMAGE_FILES = list(input_dir.rglob(\"*.jpg\"))\n",
    "        print(\"[INFO] {}\".format(fld_name))\n",
    "        for idx, file in enumerate(IMAGE_FILES):\n",
    "            file = str(file)\n",
    "        # Read an image, flip it around y-axis for correct handedness output (see\n",
    "        # above).\n",
    "            image = cv2.flip(cv2.imread(file), 1)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            if not results.multi_hand_landmarks:\n",
    "                continue\n",
    "            image_height, image_width, _ = image.shape\n",
    "            annotated_image = image.copy()\n",
    "            land_marks = {}\n",
    "            for hand_type, hand_landmarks in zip(results.multi_handedness , results.multi_hand_landmarks):\n",
    "                land_marks[hand_type.classification[0].label] = hand_landmarks\n",
    "\n",
    "            data_points.append([land_marks,fld_name])\n",
    "            print(fld_name,\" \",end = \"\")\n",
    "            # Draw hand world landmarks.\n",
    "            if not results.multi_hand_world_landmarks:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e03295",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points[0][0]['Right'].landmark[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_landmarks = data_points[-375][0]\n",
    "sample_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb5c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points[-375][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8aa1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sample_landmarks.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770be318",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1]\n",
    "l.append([0]*21)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b264bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([1] + [0]*21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8283ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean(dic):\n",
    "    len_dic = len(dic.keys())\n",
    "    features = []\n",
    "    temp = [0]*42\n",
    "    for side, item in dic.items():\n",
    "        for lm in item.landmark:\n",
    "            features.append(lm.x)\n",
    "            features.append(lm.y)\n",
    "    if len(features) == 42 and list(dic.keys())[0] == 'Right':\n",
    "        features = features + temp \n",
    "    if len(features) == 42 and list(dic.keys())[0] == 'Left':\n",
    "        features = temp + features\n",
    "#     print(features, len(features))\n",
    "    return features\n",
    "        \n",
    "clean(sample_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points[-375][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc98de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points[-375][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_points)):\n",
    "    data_points[i][0] = clean(data_points[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220e63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_points[-375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(len(data_points)):\n",
    "    x.append(data_points[i][0])\n",
    "    y.append(data_points[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)==len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d6fb5-ff17-40ce-9b44-54000372bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.DataFrame(x)\n",
    "X.to_csv('file1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x,y, test_size = 0.1, random_state=42 )\n",
    "\n",
    "# model = AdaBoostClassifier()\n",
    "model = RandomForestClassifier()\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test_y,model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a751993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a226ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "file_name = \"RF_model_full.pkl\"\n",
    "pickle.dump(model,open(file_name,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5832a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = pickle.load(open(file_name,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_y,test_model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['right'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406dd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['left'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eb876",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"datafile.pkl\"\n",
    "pickle.dump(data_points,open(data_file,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datafile = pickle.load(open(data_file,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0b7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
